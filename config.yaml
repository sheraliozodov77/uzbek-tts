# Uzbek TTS Training Configuration - Optimized for RTX 4090
# Based on VITS architecture with Common Voice v17.0 dataset
# RTX 4090: 24GB VRAM, 1008 GB/s memory bandwidth, 16384 CUDA cores

# Model Configuration
model:
  name: "vits"
  use_phonemes: true
  phoneme_language: "uz"
  use_speaker_embedding: false
  use_d_vector_file: false
  use_speaker_encoder_as_loss: false

# Dataset Configuration
dataset:
  dataset_name: "uzbek_common_voice"
  path: "./data/preprocessed"
  meta_file_train: "train_metadata.csv"
  meta_file_val: "val_metadata.csv"
  language: "uz"
  formatter: "ljspeech"
  ignored_speakers: []
  use_speaker_embedding: false
  use_d_vector_file: false
  characters:
    characters_class: "TTS.tts.utils.text.characters.Phonemes"
    characters: "abcdefghijklmnopqrstuvwxyzɑæɐɒɓɔɕɖɗɘəɚɛɜɝɞɟɠɡɢɣɤɥɦɧɨɩɪɫɬɭɮɯɰɱɲɳɴɵɶɷɸɹɺɻɼɽɾɿʀʁʂʃʄʅʆʇʈʉʊʋʌʍʎʏʐʑʒʓʔʕʖʗʘʙʚʛʜʝʞʟʠʡʢʣʤʥʦʧʨʩʪʫʬʭʮʯʰʱʲʳʴʵʶʷʸʹʺʻʼʽʾʿˀˁ˂˃˄˅ˆˇˈˉˊˋˌˍˎˏːˑ˒˓˔˕˖˗˘˙˚˛˜˝˞˟ˠˡˢˣˤ˥˦˧˨˩˪˫ˬ˭ˮ˯˰˱˲˳˴˵˶˷˸˹˺˻˼˽˾˿"
    punctuations: "!'(),-.:;? "
    phonemes: "ɑæɐɒɓɔɕɖɗɘəɚɛɜɝɞɟɠɡɢɣɤɥɦɧɨɩɪɫɬɭɮɯɰɱɲɳɴɵɶɷɸɹɺɻɼɽɾɿʀʁʂʃʄʅʆʇʈʉʊʋʌʍʎʏʐʑʒʓʔʕʖʗʘʙʚʛʜʝʞʟʠʡʢʣʤʥʦʧʨʩʪʫʬʭʮʯʰʱʲʳʴʵʶʷʸʹʺʻʼʽʾʿˀˁ˂˃˄˅ˆˇˈˉˊˋˌˍˎˏːˑ˒˓˔˕˖˗˘˙˚˛˜˝˞˟ˠˡˢˣˤ˥˦˧˨˩˪˫ˬ˭ˮ˯˰˱˲˳˴˵˶˷˸˹˺˻˼˽˾˿"
    add_blank: true

# Audio Configuration
audio:
  sample_rate: 22050
  hop_length: 256
  win_length: 1024
  n_fft: 1024
  n_mel_channels: 80
  num_mels: 80
  mel_fmin: 0
  mel_fmax: 8000
  ref_level_db: 20
  min_level_db: -100
  preemphasis: 0.98
  power: 1.5
  griffin_lim_iters: 60

# Training Configuration - Optimized for RTX 4090 (24GB VRAM)
training:
  batch_size: 96  # Increased from 32 (3x increase to leverage 24GB VRAM)
  eval_batch_size: 24  # Increased from 8 (3x increase)
  num_epochs: 200
  text_split_length: 200
  text_cleaner: "phoneme_cleaners"
  enable_eos_bos_chars: false
  num_loader_workers: 8  # Increased for better data loading
  pin_memory: true  # Enable for faster GPU transfer
  test_sentences:
    - "Salom, qandaysiz?"
    - "Bugun ob-havo juda yaxshi."
    - "Men Toshkentda yashayman."
    - "Uzbek tilida gapirishni o'rganyapman."

# Optimizer Configuration - Optimized for RTX 4090
optimizer:
  optimizer: "AdamW"
  lr: 0.0003  # Increased from 0.0001 (3x increase to match batch size scaling)
  weight_decay: 0.01
  betas: [0.8, 0.99]
  eps: 1e-9
  gradient_clip_val: 1.0  # Add gradient clipping for stability with larger batches

# Scheduler Configuration - Optimized for RTX 4090
lr_scheduler: "ExponentialLR"
lr_scheduler_params:
  gamma: 0.9999  # Slightly slower decay for better convergence with larger batches
  last_epoch: -1

# Loss Configuration
loss:
  c_mel: 45
  c_kl: 1.0

# Model Architecture - Optimized for RTX 4090
model_args:
  use_speaker_embedding: false
  use_d_vector_file: false
  d_vector_dim: 512
  num_speakers: 1
  use_speaker_encoder_as_loss: false
  speaker_encoder_config_path: ""
  speaker_encoder_model_path: ""
  resblock: "1"
  resblock_kernel_sizes: [3, 7, 11]
  resblock_dilation_sizes: [[1, 3, 5], [1, 3, 5], [1, 3, 5]]
  upsample_rates: [8, 8, 2, 2]
  upsample_initial_channel: 512
  upsample_kernel_sizes: [16, 16, 4, 4]
  inference_noise_scale: 0.667
  inference_noise_scale_w: 0.8

# Logging Configuration - Optimized for RTX 4090
logging:
  use_wandb: true
  use_mlflow: true
  wandb_project: "uzbek-tts-rtx4090"  # Updated project name
  wandb_entity: "sheraliozodov03-uzbekcomos"
  mlflow_experiment_name: "uzbek-tts-rtx4090-experiment"  # Updated experiment name
  log_model: true
  log_audio: true
  log_interval: 50  # More frequent logging with larger batches
  save_interval: 500  # More frequent saves with faster training
  eval_interval: 500  # More frequent evaluation

# Output Configuration - Optimized for RTX 4090
output_path: "./output"
save_step: 500  # More frequent saves with faster training
save_n_checkpoints: 8  # Keep more checkpoints with faster training
save_checkpoints: true
save_all_best: false
save_best_after: 5000  # Earlier best model saving

# Mixed Precision - Enable for RTX 4090
mixed_precision: true  # Enable mixed precision for better performance

# RTX 4090 Specific Optimizations
rtx4090_optimizations:
  compile_model: true  # Enable PyTorch 2.0 compilation for faster training
  use_torch_compile: true  # Use torch.compile for optimization
  memory_format: "channels_last"  # Optimize memory layout
  enable_cudnn_benchmark: true  # Enable cuDNN benchmark for consistent input sizes
  enable_cudnn_deterministic: false  # Allow non-deterministic for speed
  tf32_enabled: true  # Enable TF32 for faster training on RTX 4090

# Distributed Training
distributed:
  backend: "nccl"
  url: "tcp://localhost:54321"

# Evaluation Configuration - Optimized for RTX 4090
eval:
  test_delay_epochs: 3  # More frequent evaluation with faster training
  run_eval: true
  test_sentences_file: "test_sentences.txt"
  save_audio_samples: true
  num_audio_samples: 8  # More samples with better GPU performance
